{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quant-02-example_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgy5H1M8SFuWxFvJcQplil",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swha815/Paper_List-GPGPU/blob/master/quant_02_example_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mASTr_LRCQr1"
      },
      "source": [
        "### IV. Example\n",
        "\n",
        "Let's classify the following image.\n",
        "\n",
        "- Network: InceptionV3\n",
        "- Platform: Keras on TensorFlow\n",
        "\n",
        "![image](https://raw.githubusercontent.com/swha815/colab/main/ILSVRC2012_val_00000002.JPEG)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuVKEOVSrZIj"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.applications as keras_app\n",
        "import tensorflow.keras.preprocessing as keras_prep\n",
        "import urllib\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def print_score(pred):\n",
        "  print('{:20}{:5}'.format('Class', 'Score'))\n",
        "  print('-' * 25)\n",
        "\n",
        "  for i in pred:\n",
        "    print('{:20}{:5.3f}'.format(i[1], i[2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nffsuKDEC9HP",
        "outputId": "470d314d-c0a9-4209-ccff-c5a1242259a1"
      },
      "source": [
        "# Prepare model for ImageNet classification\n",
        "model = keras_app.InceptionV3(weights='imagenet')\n",
        "img_size = (299, 299)\n",
        "\n",
        "# Load and pre-process an image\n",
        "req = urllib.request.urlopen('https://raw.githubusercontent.com/swha815/colab/main/ILSVRC2012_val_00000002.JPEG')\n",
        "arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
        "img = org_img = cv2.imdecode(arr, -1)\n",
        "img = cv2.resize(img, img_size)\n",
        "img = np.expand_dims(img, axis=0)\n",
        "img = keras_app.inception_v3.preprocess_input(img)\n",
        "\n",
        "# Predict\n",
        "pred = model.predict(img)\n",
        "pred = keras_app.imagenet_utils.decode_predictions(pred, top=5)\n",
        "\n",
        "# Score prediction\n",
        "print_score(pred[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class               Score\n",
            "-------------------------\n",
            "ski                 0.803\n",
            "alp                 0.070\n",
            "ski_mask            0.005\n",
            "mountain_tent       0.003\n",
            "shovel              0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9FtAZ9XoApk"
      },
      "source": [
        "### V. Weight Quantization\n",
        "\n",
        "Empirically, quantization of weights is best achieved based on max-magnitude of the values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hJkz65a4ai1"
      },
      "source": [
        "#### Profile and Analyze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjksJmTw1b_v"
      },
      "source": [
        "weight_prof_dict = dict()\n",
        "\n",
        "for layer in model.layers:\n",
        "  if not isinstance(layer, tf.keras.layers.Conv2D):\n",
        "    continue\n",
        "\n",
        "  w = layer.get_weights()\n",
        "  w_max = np.amax(w[0], axis=(0, 1))\n",
        "  w_min = np.amin(w[0], axis=(0, 1))\n",
        "\n",
        "  weight_prof_dict[layer.name] = (w_max, w_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIcp7VmT4MqQ"
      },
      "source": [
        "##### Decide and Simulate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ZtXQpo5x1L"
      },
      "source": [
        "bits = 8\n",
        "signed = True\n",
        "verbose = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHmjGDmN4wxI"
      },
      "source": [
        "def get_int_range(bits, signed):\n",
        "  if bits <= 0 or not isinstance(bits, int):\n",
        "    raise Exception('Invalid bits specification.')\n",
        "\n",
        "  if not isinstance(signed, bool):\n",
        "    raise Exception('Invalid signed specification.')\n",
        "\n",
        "  if signed:\n",
        "    int_max = 2 ** (bits - 1) - 1\n",
        "    int_min = -(2 ** (bits - 1))\n",
        "  else:\n",
        "    int_max = 2 ** bits - 1\n",
        "    int_min = 0\n",
        "\n",
        "  return (int_max, int_min)\n",
        "\n",
        "\n",
        "def get_sf(signed, int_max, int_min, real_max, real_min):\n",
        "  if np.any(real_max < real_min):\n",
        "    raise Exception('Max is smaller than min.')\n",
        "\n",
        "  if len(real_max) != len(real_min):\n",
        "    raise Exception('real_max and real_min must be of equal lenghts.')\n",
        "\n",
        "  if not isinstance(signed, bool):\n",
        "    raise Exception('Invalid signed specification.')\n",
        "\n",
        "  if signed:\n",
        "    sf_max = np.divide(int_max, real_max,\n",
        "        out=np.ones_like(real_max), where=(real_max != 0))\n",
        "    sf_min = np.divide(int_min, real_min,\n",
        "        out=np.ones_like(real_min), where=(real_min != 0))\n",
        "    sf = np.minimum(np.abs(sf_min), np.abs(sf_max))\n",
        "  else:\n",
        "    sf = np.divide(int_max, real_max,\n",
        "        out=np.ones_like(real_max), where=(real_max != 0))\n",
        "    sf = np.abs(sf)\n",
        "\n",
        "  return sf\n",
        "\n",
        "\n",
        "def quantize_numpy(org_vals, scale_factor, int_max, int_min):\n",
        "  qvals = np.multiply(org_vals, scale_factor)\n",
        "  qvals = np.minimum(int_max, qvals)\n",
        "  qvals = np.maximum(int_min, qvals)\n",
        "  qvals = np.round(qvals)\n",
        "  qvals = np.divide(qvals, scale_factor)\n",
        "\n",
        "  return qvals\n",
        "\n",
        "\n",
        "def compress_model_param(model, bits, signed):\n",
        "  log = list()\n",
        "\n",
        "  for layer in model.layers:\n",
        "    if not layer.name in weight_prof_dict.keys():\n",
        "      continue\n",
        "\n",
        "    w = layer.get_weights()\n",
        "    w_max = weight_prof_dict[layer.name][0]\n",
        "    w_min = weight_prof_dict[layer.name][1]\n",
        "\n",
        "    # calculate scale factor\n",
        "    int_max, int_min = get_int_range(bits, signed)\n",
        "    sf = get_sf(signed, int_max, int_min, w_max, w_min)\n",
        "    \n",
        "    # quantize weights with given scale factor\n",
        "    qvals = quantize_numpy(w[0], sf, int_max, int_min)\n",
        "    quant_loss = np.sum((w[0] - qvals) ** 2)\n",
        "\n",
        "    # store quantized weights\n",
        "    w[0] = qvals\n",
        "    layer.set_weights(w)\n",
        "\n",
        "    log.append([layer.name, bits, signed, quant_loss])\n",
        "\n",
        "  return (model, log)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7H_ENy07she",
        "outputId": "f0fac0bf-9d76-464c-bb83-cc937b1b0bc2"
      },
      "source": [
        "# Quantize weights\n",
        "qmodel, qlog = compress_model_param(model, bits, signed)\n",
        "\n",
        "if verbose == True:\n",
        "  print('Layer Parameter Loss')\n",
        "\n",
        "  for l in qlog:\n",
        "    print('  {} [{}b-{}] loss: {:.3f}'.format(l[0], l[1], l[2], l[3]))\n",
        "\n",
        "total_loss = np.sum(np.array(qlog)[:, 3].astype(float))\n",
        "print('Compressed {} layers (total loss: {:.3f})\\n'.format(len(qlog), total_loss))\n",
        "\n",
        "# Predict\n",
        "qpred = qmodel.predict(img)\n",
        "qpred = keras_app.imagenet_utils.decode_predictions(qpred, top=5)\n",
        "\n",
        "# Score prediction\n",
        "print_score(qpred[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compressed 94 layers (total loss: 0.000)\n",
            "\n",
            "Class               Score\n",
            "-------------------------\n",
            "ski                 0.804\n",
            "alp                 0.073\n",
            "ski_mask            0.005\n",
            "mountain_tent       0.003\n",
            "shovel              0.001\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}